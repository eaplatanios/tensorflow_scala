# Release 0.2.0

In this release we have:

  - Added support for incremental compilation.
  - Added support for [Horovod](https://github.com/uber/horovod).
  - Added support for timelines to allow for easy profiling of
    TensorFlow graphs.
  - Fixed a major memory leak (issue #87).
  - Updated the JNI bindings to be compatible with the TensorFlow
    1.9.0 release.
  - Added support for obtaining the list of available devices from
    within Scala.
  - Fixed bugs for some control flow ops.
  - Added support for `tf.cases`.
  - Added support for the RMSProp optimizer, the lazy Adam optimizer,
    the [AMSGrad](https://openreview.net/pdf?id=ryQu7f-RZ) optimizer,
    the lazy AMSGrad optimizer, and the
    [YellowFin](https://arxiv.org/pdf/1706.03471.pdf) optimizer.
  - Added more learning rate decay schemes:
    - Cosine decay.
    - Cycle-linear 10x decay.
    - Square-root decay.
    - More warm-up decay schedules.
  - Added support for dataset interleave ops.
  - Fixed some bugs related to variable scopes and variable sharing.
  - Fixed some bugs related to functional ops.
  - Added support for some new image-related ops, under the namespace
    `tf.image`.
  - Improved consistency for the creation of initializer ops.
  - Added support for the `tf.initializer` op creation context.
  - Exposed part of the `TensorArray` API.
  - Exposed `tf.Op.Builder` in the public API.
  - Improvements to the learn API:
    - Refactored `mode` into an implicit argument.
    - Improved the evaluator hook.
    - Removed the layer creation context mechanism, to be refactored
      later. It was causing some issues due to bad design and unclear
      semantics. The plan is to implement this, in the near future, as
      wrapper creation context layers.
    - Improved the `Model` class.
    - Fixed a bug that was causing some issues related to inference
      hooks in the in-memory estimator.
    - Improved logging.
  - Added support for reading and writing numpy (i.e., `.npy`) files.
  - Added a logo. :)
